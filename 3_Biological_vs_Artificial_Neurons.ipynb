{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "785455e8",
   "metadata": {},
   "source": [
    "## Bridging Biological and Artificial Intelligence\n",
    "\n",
    "This notebook explores how biological neurons (Hodgkin-Huxley model) relate to artificial neurons in deep learning. Understanding these parallels lies at the heart of **NeuroAI**, using neuroscience to inspire AI, and AI to understand the brain.\n",
    "\n",
    "**Learning Goals**\n",
    "- Understand differences between biological and artificial neurons\n",
    "- Explore insights from neuroscience that inform AI\n",
    "- Relate the Hodgkin-Huxley model to modern architectures\n",
    "- Connect parameter inference in biology and AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d548c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"pyHH/src\")\n",
    "from pyhh import HHModel, Simulation\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9d37fb",
   "metadata": {},
   "source": [
    "### Simulating a Biological Neuron\n",
    "\n",
    "Generate a typical action potential using the Hodgkin-Huxley model (biologically grounded description of a neuron’s response to input current) using `pyhh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f66160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulating 20000 time points...\n",
      "simulation complete\n",
      "Simulated 20000 points (200.0 ms)\n",
      "Peak voltage: 104.32 mV\n",
      "Resting voltage: -0.01 mV\n"
     ]
    }
   ],
   "source": [
    "def simulate_hh_spike(V_rest=50.0, stim_amplitude=5.0):\n",
    "    \"\"\"Simulate HH model and return membrane potential trace.\"\"\"\n",
    "    model = HHModel()\n",
    "    model.V_rest = V_rest\n",
    "    \n",
    "    stim = np.zeros(20000)\n",
    "    stim[7000:13000] = stim_amplitude  # 60 ms pulse\n",
    "    \n",
    "    sim = Simulation(model)\n",
    "    sim.Run(stimulusWaveform=stim, stepSizeMs=0.01)\n",
    "    return sim.Vm\n",
    "\n",
    "hh_voltage = simulate_hh_spike()\n",
    "time_hh = np.arange(len(hh_voltage)) * 0.01\n",
    "\n",
    "print(f\"Simulated {len(hh_voltage)} points ({time_hh[-1]:.1f} ms)\")\n",
    "print(f\"Peak voltage: {np.max(hh_voltage):.2f} mV\")\n",
    "print(f\"Resting voltage: {hh_voltage[0]:.2f} mV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c34cf4d",
   "metadata": {},
   "source": [
    "### Artificial Neuron Activation Functions\n",
    "\n",
    "Artificial neurons use simple nonlinear functions (ReLU, sigmoid, tanh) to introduce complexity. Let’s define and visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "021a2887",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-80, 40, 1000)\n",
    "\n",
    "def relu(x): return np.maximum(0, x + 65)\n",
    "def sigmoid(x): return 100 / (1 + np.exp(-x/10))\n",
    "def tanh(x): return 50 * np.tanh(x/20) + 50\n",
    "def leaky_relu(x, alpha=0.01): return np.where(x > -65, x + 65, alpha * (x + 65))\n",
    "\n",
    "relu_vals = relu(x)\n",
    "sigmoid_vals = sigmoid(x)\n",
    "tanh_vals = tanh(x)\n",
    "leaky_relu_vals = leaky_relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9ace03",
   "metadata": {},
   "source": [
    "### Visual Comparison\n",
    "\n",
    "Compare biological and artificial neuron responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f767338",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1869904564.py, line 26)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31max2.plot(x, 100 * (1 / (1 + np.exp(-x/10))), '--' color='orange', linewidth=2.5, label='Sigmoid')\u001b[39m\n                                                 ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle(\"Biological vs Artificial Neurons\", fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "# Left: Biological Neuron (Hodgkin–Huxley)\n",
    "ax1 = axes[0]\n",
    "ax1.plot(time_hh, hh_voltage, color='royalblue', linewidth=2.5, label='HH Membrane Potential')\n",
    "ax1.axhline(-65, color='gray', linestyle='--', alpha=0.6, label='Resting potential (-65 mV)')\n",
    "ax1.axhline(0, color='red', linestyle='--', alpha=0.4, label='Spike threshold (0 mV)')\n",
    "ax1.axvspan(70, 130, alpha=0.1, color='gold', label='Stimulus period')\n",
    "\n",
    "ax1.set_title(\"Biological Neuron (Hodgkin–Huxley Model)\", fontsize=13, fontweight='bold')\n",
    "ax1.set_xlabel(\"Time (ms)\", fontsize=11)\n",
    "ax1.set_ylabel(\"Membrane Potential (mV)\", fontsize=11)\n",
    "ax1.set_xlim(0, 200)\n",
    "ax1.set_ylim(-70, 120)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend(fontsize=9, loc='upper right')\n",
    "\n",
    "ax1.annotate('Action Potential', xy=(95, 35), xytext=(135, 30),\n",
    "             arrowprops=dict(arrowstyle='->', lw=2, color='red'),\n",
    "             fontsize=10, color='red', fontweight='bold')\n",
    "\n",
    "\n",
    "# Right: Artificial Neuron Activation Functions\n",
    "ax2 = axes[1]\n",
    "ax2.plot(x, 100 * (1 / (1 + np.exp(-x/10))), '--', color='orange', linewidth=2.5, label='Sigmoid')\n",
    "ax2.plot(x, 50 * np.tanh(x/20) + 50, color='green', linewidth=2.5, label='Tanh')\n",
    "ax2.plot(x, np.maximum(0, x + 65), color='purple', linewidth=2.5, label='ReLU')\n",
    "ax2.plot(x, np.where(x > -65, x + 65, 0.01 * (x + 65)), '--', color='magenta', linewidth=2.0, label='Leaky ReLU')\n",
    "\n",
    "# Add reference lines\n",
    "ax2.axvline(-65, color='gray', linestyle='--', alpha=0.6)\n",
    "ax2.axvline(0, color='red', linestyle='--', alpha=0.4)\n",
    "ax2.text(-72, 105, 'Resting', color='gray', fontsize=9)\n",
    "ax2.text(3, 105, 'Threshold', color='red', fontsize=9)\n",
    "\n",
    "ax2.set_title(\"Artificial Neurons (Activation Functions)\", fontsize=13, fontweight='bold')\n",
    "ax2.set_xlabel(\"Input (a.u.)\", fontsize=11)\n",
    "ax2.set_ylabel(\"Output (a.u.)\", fontsize=11)\n",
    "ax2.set_xlim(-80, 40)\n",
    "ax2.set_ylim(-10, 110)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend(fontsize=9, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c7aabb",
   "metadata": {},
   "source": [
    "### Quantitative Comparison\n",
    "\n",
    "Compare biological (HH) and artificial neurons on key computational properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0af0a177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "QUANTITATIVE COMPARISON: BIOLOGICAL vs ARTIFICIAL\n",
      "======================================================================\n",
      "Spike duration: 138.76 ms\n",
      "Spike count: 5\n",
      "Peak voltage: 104.32 mV\n",
      "Range: 115.0 mV\n",
      "\n",
      "Artificial neurons:\n",
      " - Instantaneous, continuous outputs\n",
      " - ReLU: piecewise linear; Sigmoid/Tanh: smooth & bounded\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"QUANTITATIVE COMPARISON: BIOLOGICAL vs ARTIFICIAL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Spike duration\n",
    "spike_indices = np.where(hh_voltage > 0)[0]\n",
    "if len(spike_indices) > 0:\n",
    "    spike_duration = (spike_indices[-1] - spike_indices[0]) * 0.01\n",
    "    print(f\"Spike duration: {spike_duration:.2f} ms\")\n",
    "\n",
    "# Spike count\n",
    "spike_count = np.sum((hh_voltage[:-1] < 0) & (hh_voltage[1:] > 0))\n",
    "print(f\"Spike count: {spike_count}\")\n",
    "print(f\"Peak voltage: {np.max(hh_voltage):.2f} mV\")\n",
    "print(f\"Range: {np.max(hh_voltage)-np.min(hh_voltage):.1f} mV\")\n",
    "\n",
    "print(\"\\nArtificial neurons:\")\n",
    "print(\" - Instantaneous, continuous outputs\")\n",
    "print(\" - ReLU: piecewise linear; Sigmoid/Tanh: smooth & bounded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e75e402",
   "metadata": {},
   "source": [
    "### Insights: Bridging biological and artificial intelligence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a219489a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Spiking Neural Networks\n",
      "────────────────────────────────────────────────────────────\n",
      "  Biological: Time-dependent spikes encode info\n",
      "  Artificial: Standard ANNs are timeless\n",
      "  NeuroAI Idea: Add temporal dynamics → event-driven computation\n",
      "\n",
      "Energy Efficiency\n",
      "────────────────────────────────────────────────────────────\n",
      "  Biological: Sparse spiking activity\n",
      "  Artificial: Dense computation (all neurons active)\n",
      "  NeuroAI Idea: Event-driven computation saves energy\n",
      "\n",
      "Parameter Inference\n",
      "────────────────────────────────────────────────────────────\n",
      "  Biological: Estimate HH parameters\n",
      "  Artificial: Learn ANN weights\n",
      "  NeuroAI Idea: Both optimize parameters for target behavior\n"
     ]
    }
   ],
   "source": [
    "insights = [\n",
    "    (\"Spiking Neural Networks\", \"Time-dependent spikes encode info\", \n",
    "     \"Standard ANNs are timeless\", \n",
    "     \"Add temporal dynamics → event-driven computation\"),\n",
    "    (\"Energy Efficiency\", \"Sparse spiking activity\", \n",
    "     \"Dense computation (all neurons active)\", \n",
    "     \"Event-driven computation saves energy\"),\n",
    "    (\"Parameter Inference\", \"Estimate HH parameters\", \n",
    "     \"Learn ANN weights\", \n",
    "     \"Both optimize parameters for target behavior\"),\n",
    "]\n",
    "\n",
    "for title, bio, art, idea in insights:\n",
    "    print(f\"\\n{title}\\n\" + \"─\"*60)\n",
    "    print(f\"  Biological: {bio}\")\n",
    "    print(f\"  Artificial: {art}\")\n",
    "    print(f\"  NeuroAI Idea: {idea}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86361ab",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- **Biological neurons** are dynamic, sparse, and energy-efficient  \n",
    "- **Artificial neurons** are simple, fast, and parallel  \n",
    "- **NeuroAI** combines both approaches for interpretable, efficient intelligence  \n",
    "- **Your parameter inference project** connects Bayesian neuroscience with machine learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
